{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will:\n",
    "\n",
    "- Remove duplicate results.\n",
    "- Fill missing values that can be filled.\n",
    "- Drop missing values that can't be filled.\n",
    "- Remove non-informative columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('../data/raw/')\n",
    "titanic_train = pd.read_csv(DATA_PATH/'train.csv')\n",
    "titanic_test = pd.read_csv(DATA_PATH/'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set duplicates: 0\n",
      "Test set duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'Training set duplicates: {titanic_train.duplicated().sum()}')\n",
    "print(f'Test set duplicates: {titanic_test.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicates in our data so no work to be done here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embarked\n",
    "\n",
    "We have missing embarked values in our training set. The most sensible option, as there is fairly few missing values, is to fill the missing values with the most common response for embarked. This is Southampton (S)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train['Embarked'] = titanic_train['Embarked'].fillna('S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fare\n",
    "\n",
    "We have one missing value in our test data for Fare. One sensible solution would be to fill this missing value based on the median fare for passengers in the same class. I am using the median here as the data contains some outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the median fare for each Pclass\n",
    "fare_medians = titanic_train.groupby('Pclass')['Fare'].median()\n",
    "# Replace missing values with median for passengers Pclass\n",
    "titanic_test['Fare'] = titanic_test.apply(\n",
    "    lambda x: np.nan_to_num(x['Fare'],nan=fare_medians[x['Pclass']]),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cabin\n",
    "\n",
    "The cabin seems to be a column that we could help to engineer a position on the boat for some passengers so we don't want to get rid of it. I will fill any missing values with a placeholder that can be used to engineer a feature from later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data missing cabins ratio: 0.7710437710437711\n",
      "Test data missing cabins: 0.7822966507177034\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training data missing cabins ratio: {titanic_train['Cabin'].isnull().sum()/len(titanic_train)}\")\n",
    "print(f\"Test data missing cabins: {titanic_test['Cabin'].isnull().sum()/len(titanic_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train['Cabin'] = titanic_train['Cabin'].fillna('N/A')\n",
    "titanic_test['Cabin'] = titanic_test['Cabin'].fillna('N/A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age\n",
    "\n",
    "Age could be an important predictor for survival so we will need to decide how best to fill any missing values. We have a few options:\n",
    "- Fill using mean/median.\n",
    "- Use another column with high correlation to fill missing values.\n",
    "- Use a machine learning algorithm to predict age based on other columns.\n",
    "\n",
    "We have already computed the mean/median above so I'll have a look at correlations between other columns and Age now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data missing age values: 177\n",
      "Test data missing age values: 86\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training data missing age values: {titanic_train['Age'].isnull().sum()}\")\n",
    "print(f\"Test data missing age values: {titanic_test['Age'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fare           0.096067\n",
       "PassengerId    0.036847\n",
       "Survived      -0.077221\n",
       "Parch         -0.189119\n",
       "SibSp         -0.308247\n",
       "Pclass        -0.369226\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train.corr()['Age'].sort_values(ascending=False)[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no columns with great correlation to age but we do learn some interesting facts:\n",
    "\n",
    "- There is a negative correlation between Pclass and Age. This would indicate that lower classes had a higher number of older passengers.\n",
    "- There is a negative correlation between Age and SibSp. This would make sense as SibSp was a count of number of siblings or spouses on the ship. As you can only have one spouse any number higher than one would indicate a passenger travelling with a sibling. It would make sense for it to be more likely to be a younger passenger (child) if the passenger was travelling with siblings.\n",
    "- There was a negative correlation between Age and Parch. This also makes sense as if a child was travelling with parents, Parch would be higher.\n",
    "\n",
    "From this information, I think the best way to fill in the missing data would be by using a machine learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age_predictors(data_frame):\n",
    "    \"\"\"\n",
    "    Returns a data frame with only the required columns needed for the age predicting model.\n",
    "    \"\"\"\n",
    "    needed_columns = ['Fare', 'Parch', 'SibSp', 'Pclass', 'Sex', 'Age']\n",
    "    age_predictors_df = pd.get_dummies(data_frame[needed_columns], drop_first=True)\n",
    "    \n",
    "    return age_predictors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 714 entries, 0 to 890\n",
      "Data columns (total 5 columns):\n",
      "Fare        714 non-null float64\n",
      "Parch       714 non-null int64\n",
      "SibSp       714 non-null int64\n",
      "Pclass      714 non-null int64\n",
      "Sex_male    714 non-null uint8\n",
      "dtypes: float64(1), int64(3), uint8(1)\n",
      "memory usage: 28.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Create our training data for Age\n",
    "age_predictors_df = get_age_predictors(titanic_train).dropna()\n",
    "age_predictors, age_target = age_predictors_df.drop('Age', axis=1), age_predictors_df['Age']\n",
    "age_predictors.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem we face now is which machine learning model do we use to predict the age. We only have a data set which has 714 entries, which limits our options. We also don't want a too complex model that takes a long time to train. I will try the lasso and elastic net models with cross validation to model the age. I'm using these methods as they produce a model with less variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2365634914181899\n",
      "[-0.01730285 -0.74636471 -3.75835274 -6.85956611  2.91621768]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "lasso = LassoCV(cv=5, random_state=0).fit(age_predictors, age_target)\n",
    "print(lasso.score(age_predictors, age_target))\n",
    "print(lasso.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2325918121972903\n",
      "[-0.010343   -0.96934404 -3.53365767 -5.92987943  2.08938831]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "enet = ElasticNetCV(cv=10, random_state=0).fit(age_predictors, age_target)\n",
    "print(enet.score(age_predictors, age_target))\n",
    "print(enet.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lasso model seems to give a slightly better R<sup>2</sup> score and so I will use this to predict the missing age values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_missing_age(dataframe, model):\n",
    "    age_predictors_df = get_age_predictors(dataframe)\n",
    "    predictors = ['Fare','Parch','SibSp','Pclass','Sex_male']\n",
    "    dataframe['Age'] = age_predictors_df.apply(\n",
    "        lambda x: np.nan_to_num(x['Age'], nan=max(model.predict(x[predictors].to_numpy().reshape(1, -1))[0],0)),\n",
    "        axis=1,\n",
    "    )\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train = predict_missing_age(titanic_train, lasso)\n",
    "titanic_test = predict_missing_age(titanic_test, lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the lasso model to predict the missing ages. If the model returned a negative value I set this to zero. I think this is a much better way of predicting the age of each passenger than using the mean or median as it uses more of the information available to me.\n",
    "\n",
    "Let's check we have filled any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data missing values: 0\n",
      "Test data missing values: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'Training data missing values: {titanic_train.isnull().sum().sum()}')\n",
    "print(f'Test data missing values: {titanic_test.isnull().sum().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Non-informative Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns I will drop are the PassengerId and the Ticket. Although, I've realised to submit solutions to kaggle I will need the PassengerId column for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = titanic_test['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train.drop(['PassengerId', 'Ticket'], axis=1, inplace=True)\n",
    "titanic_test.drop(['PassengerId', 'Ticket'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data sets have now been cleaned and are ready for feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      "Survived    891 non-null int64\n",
      "Pclass      891 non-null int64\n",
      "Name        891 non-null object\n",
      "Sex         891 non-null object\n",
      "Age         891 non-null float64\n",
      "SibSp       891 non-null int64\n",
      "Parch       891 non-null int64\n",
      "Fare        891 non-null float64\n",
      "Cabin       891 non-null object\n",
      "Embarked    891 non-null object\n",
      "dtypes: float64(2), int64(4), object(4)\n",
      "memory usage: 69.7+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_PATH = Path('../data/processed')\n",
    "test_ids.to_csv(PROCESSED_PATH/'test_ids.csv', index=False, header='PassengerId')\n",
    "titanic_train.to_csv(PROCESSED_PATH/'cleaned_training.csv', index=False)\n",
    "titanic_test.to_csv(PROCESSED_PATH/'cleaned_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "berlin_airbnb",
   "language": "python",
   "name": "berlin_airbnb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
