{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.feature_selection import RFECV, SelectKBest, chi2\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will try a few different techniques to find the best model. The process I will take are:\n",
    "\n",
    "1. Produce a baseline model using all variables.\n",
    "2. Use univariate selection to create a subset of features to improve my baseline model.\n",
    "3. Use recursive feature elimination to create another subset of features to train a model with.\n",
    "4. Train a number of different models with my final subset of features to find the most appropriate model.\n",
    "5. Tune parameters in final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "DATA_PATH = Path('../data/processed/')\n",
    "training_no_dummies = pd.read_csv(DATA_PATH/'final_training.csv')\n",
    "test_no_dummies = pd.read_csv(DATA_PATH/'final_test.csv')\n",
    "training_df = pd.read_csv(DATA_PATH/'final_training_w_dummies.csv')\n",
    "test_df = pd.read_csv(DATA_PATH/'final_test_w_dummies.csv')\n",
    "test_ids = pd.read_csv(DATA_PATH/'test_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 16 columns):\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Fare           891 non-null float64\n",
      "Deck           891 non-null int64\n",
      "Relatives      891 non-null int64\n",
      "Child          891 non-null int64\n",
      "Sex_male       891 non-null int64\n",
      "Embarked_Q     891 non-null int64\n",
      "Embarked_S     891 non-null int64\n",
      "Title_Miss     891 non-null int64\n",
      "Title_Mr       891 non-null int64\n",
      "Title_Mrs      891 non-null int64\n",
      "Title_Other    891 non-null int64\n",
      "dtypes: float64(2), int64(14)\n",
      "memory usage: 111.5 KB\n"
     ]
    }
   ],
   "source": [
    "training_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I will produce a metrics function so I can produce all the desired metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metrics(model, X, y_true):\n",
    "    \"\"\"Prints accuracy, f1 and confusion matrix for classification model.\"\"\"\n",
    "    predictions = model.predict(X)\n",
    "    print(f'Accuracy score: {accuracy_score(y_true, predictions)}')\n",
    "    print(f'F1 score: {f1_score(y_true, predictions)}')\n",
    "    print('\\n')\n",
    "    print(pd.crosstab(pd.Series(predictions, name='Predicted'), pd.Series(y_true, name='Actual')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "\n",
    "I will start by creating a baseline model using logistic regression. As our test set doesn't include target variable, I will use cross validation to get a more accurate estimate of the performance of the model than if I were to train once on the entire training set and then evaluate using the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictor set and target variable\n",
    "X_train = training_df.drop('Survived', axis=1)\n",
    "y_train = training_df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.8338945005611672\n",
      "F1 score: 0.7791044776119402\n",
      "\n",
      "\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "0          482   81\n",
      "1           67  261\n"
     ]
    }
   ],
   "source": [
    "baseline_lr = LogisticRegressionCV(cv=10).fit(X_train, y_train)\n",
    "generate_metrics(baseline_lr, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Feature Selection\n",
    "\n",
    "To compare the variables in our model we need to convert any continuous data to discrete by putting the continuous data into bins and any nominal data we will encode using discrete values to be a value input for sklearn chi2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuous_to_discrete(dataframe):\n",
    "    \"\"\"Creates new dataframe with continuous data put in bins.\"\"\"\n",
    "    continuous = dataframe.dtypes[dataframe.dtypes == np.float64].index\n",
    "    discrete_df = dataframe.drop(continuous, axis=1)\n",
    "    for column in continuous:\n",
    "        discrete_df = pd.concat([discrete_df, pd.cut(dataframe[column], 20)], axis=1)\n",
    "        \n",
    "    return discrete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_encoder(dataframe):\n",
    "    \"\"\"Encodes columns using discrete values.\"\"\"\n",
    "    ordinal_encoder = OrdinalEncoder().fit(dataframe)\n",
    "    return pd.DataFrame(ordinal_encoder.transform(dataframe), columns=dataframe.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we transform our data to a form that the chi2 function can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_form(dataframe):\n",
    "    \"\"\"Transforms dataframe to form accepted by sklearn chi2.\"\"\"\n",
    "    discrete_df = continuous_to_discrete(dataframe)\n",
    "    discrete_df = ordinal_encoder(discrete_df)\n",
    "    return discrete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_chi2 = chi2_form(training_no_dummies)\n",
    "X_chi2 = training_chi2.drop('Survived', axis=1)\n",
    "y_chi2 = training_chi2['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using sklearn's chi2 and SelectKBest functions we can find the most associated features with survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selector = SelectKBest(chi2, k=8).fit(X_chi2, y_chi2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets display our features in order of the p values obtained by performing the chi squared test on each variable with the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>P Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fare</td>\n",
       "      <td>3.246186e-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sex</td>\n",
       "      <td>6.077838e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Deck</td>\n",
       "      <td>1.038247e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>1.581715e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>1.402485e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parch</td>\n",
       "      <td>1.484707e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Age</td>\n",
       "      <td>9.063848e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Child</td>\n",
       "      <td>2.517566e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Relatives</td>\n",
       "      <td>2.141910e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>2.662355e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Title</td>\n",
       "      <td>3.654606e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature       P Value\n",
       "10       Fare  3.246186e-48\n",
       "1         Sex  6.077838e-22\n",
       "5        Deck  1.038247e-13\n",
       "0      Pclass  1.581715e-13\n",
       "4    Embarked  1.402485e-03\n",
       "3       Parch  1.484707e-03\n",
       "9         Age  9.063848e-03\n",
       "8       Child  2.517566e-02\n",
       "6   Relatives  2.141910e-01\n",
       "2       SibSp  2.662355e-01\n",
       "7       Title  3.654606e-01"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features_df = pd.DataFrame({'Feature':list(X_chi2.columns), 'P Value':feature_selector.pvalues_})\n",
    "selected_features_df.sort_values(by='P Value', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train our model using the K best features. I will use the continuous data again, where applicable, and convert any categorical columns to dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_chi2_selected = training_no_dummies[X_chi2.columns[feature_selector.get_support()]]\n",
    "X_chi2_selected = pd.get_dummies(X_chi2_selected, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.8013468013468014\n",
      "F1 score: 0.7338345864661654\n",
      "\n",
      "\n",
      "Actual     0.0  1.0\n",
      "Predicted          \n",
      "0.0        470   98\n",
      "1.0         79  244\n"
     ]
    }
   ],
   "source": [
    "chi_selected_lr = LogisticRegressionCV(cv=10).fit(X_chi2_selected, y_chi2)\n",
    "generate_metrics(chi_selected_lr, X_chi2_selected, y_chi2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This hasn't imporoved our model, which indicates using more features could be useful for training our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination\n",
    "\n",
    "We can use recursive feature elimination to find an optimal subset of features to train on. First we will scale our variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "scaled_X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to train our recursive feature eliminator. We will use a logistic regression model as our estimator to assess the accuracy at each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = LogisticRegression()\n",
    "selector = RFECV(estimator, step=1, cv=10, scoring='accuracy')\n",
    "selector = selector.fit(scaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.n_features_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By doing our recursive feature elimination we have found an optimal subset of features to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.8372615039281706\n",
      "F1 score: 0.7826086956521738\n",
      "\n",
      "\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "0          485   81\n",
      "1           64  261\n"
     ]
    }
   ],
   "source": [
    "RFE_selected_X = pd.DataFrame(selector.transform(scaled_X_train), columns=X_train.columns[selector.get_support()])\n",
    "rfe_lr = LogisticRegressionCV(cv=10).fit(RFE_selected_X, y_train)\n",
    "generate_metrics(rfe_lr, RFE_selected_X, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a slight improvement over our baseline model, lets train a selection of models using this subset of features to see if we can improve on the accuracy of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "As we don't have a test set to evaluate our models with, we will use cross validation to estimate the accuracy of our models and create confidence intervals using the t distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_mean_std(model, X, y, score_func):\n",
    "    \"\"\"\n",
    "    Calculates and prints the mean and standard deviation for the scoring function based on\n",
    "    a 10 fold cross validation.\n",
    "    \"\"\"\n",
    "    scores = cross_val_score(model, X, y, scoring=score_func, cv=10)\n",
    "    mean = round(scores.mean(), 3)\n",
    "    standard_deviation = round(scores.std(), 3)\n",
    "    print(f'Scoring function: {score_func}')\n",
    "    print(f'Mean score: {mean}')\n",
    "    print(f'Standard deviation of scores: {standard_deviation}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring function: accuracy\n",
      "Mean score: 0.8\n",
      "Standard deviation of scores: 0.05\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier().fit(RFE_selected_X, y_train)\n",
    "cross_val_mean_std(dtc, RFE_selected_X, y_train, 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring function: accuracy\n",
      "Mean score: 0.813\n",
      "Standard deviation of scores: 0.047\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(random_state=0).fit(RFE_selected_X, y_train)\n",
    "cross_val_mean_std(forest, RFE_selected_X, y_train, 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring function: accuracy\n",
      "Mean score: 0.836\n",
      "Standard deviation of scores: 0.036\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(gamma='auto').fit(RFE_selected_X, y_train)\n",
    "cross_val_mean_std(svc, RFE_selected_X, y_train, 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring function: accuracy\n",
      "Mean score: 0.823\n",
      "Standard deviation of scores: 0.032\n"
     ]
    }
   ],
   "source": [
    "KNN = KNeighborsClassifier().fit(RFE_selected_X, y_train)\n",
    "cross_val_mean_std(KNN, RFE_selected_X, y_train, 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems SVC may be the best method to use for this problem, now we should try parameter tuning to create the best model feasible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning\n",
    "\n",
    "We will use a grid search to find the optimal parameters to produce the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_parameters = [\n",
    "    {\n",
    "        'C': [0.001,0.01,0.1,1,10,20,50,100],\n",
    "        'gamma': [1,0.1,0.01,0.001],\n",
    "        'kernel': ['rbf', 'sigmoid']\n",
    "    },\n",
    "    {\n",
    "        'C': [0.001,0.01,0.1,1, 10],\n",
    "        'gamma': [1,0.1,0.01,0.001],\n",
    "        'kernel': ['poly']\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 84 candidates, totalling 420 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 420 out of 420 | elapsed:   23.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid=[{'C': [0.001, 0.01, 0.1, 1, 10, 20, 50, 100],\n",
       "                          'gamma': [1, 0.1, 0.01, 0.001],\n",
       "                          'kernel': ['rbf', 'sigmoid']},\n",
       "                         {'C': [0.001, 0.01, 0.1, 1, 10],\n",
       "                          'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['poly']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_parameter_search = GridSearchCV(SVC(), search_parameters, cv=5, verbose=2, n_jobs =-1)\n",
    "svc_parameter_search.fit(RFE_selected_X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 20, 'gamma': 0.01, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_parameter_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have found the optimal parameters we can estimate the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring function: accuracy\n",
      "Mean score: 0.834\n",
      "Standard deviation of scores: 0.038\n"
     ]
    }
   ],
   "source": [
    "cross_val_mean_std(svc_parameter_search.best_estimator_, RFE_selected_X, y_train, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.8406285072951739\n",
      "F1 score: 0.7835365853658537\n",
      "\n",
      "\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "0          492   85\n",
      "1           57  257\n"
     ]
    }
   ],
   "source": [
    "generate_metrics(svc_parameter_search.best_estimator_, RFE_selected_X, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the trained model to predict the survival of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test = pd.DataFrame(scaler.transform(test_df), columns=test_df.columns)\n",
    "X_test = pd.DataFrame(selector.transform(scaled_test), columns=scaled_test.columns[selector.get_support()])\n",
    "test_predictions = pd.DataFrame({\n",
    "    'PassengerId': test_ids.values.T.flatten(), \n",
    "    'Survived': svc_parameter_search.best_estimator_.predict(X_test)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED_DATA_PATH = Path('../data/predictions/')\n",
    "test_predictions.to_csv(PRED_DATA_PATH/'predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "berlin_airbnb",
   "language": "python",
   "name": "berlin_airbnb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
